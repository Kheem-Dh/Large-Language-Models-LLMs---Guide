{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Seq2Seq Models\n",
        "\n",
        "Sequence-to-Sequence (Seq2Seq) models are a type of model that convert sequences from one domain to sequences in another domain. These models are particularly useful for tasks that involve generating sequences as outputs based on sequential inputs. Common applications include machine translation, where the input sequence is text in the source language, and the output sequence is the corresponding text in the target language. Other applications involve speech recognition, text summarization, and question answering.\n",
        "\n",
        "## Understanding the Components\n",
        "\n",
        "Seq2Seq models typically consist of two main components:\n",
        "\n",
        "### Encoder\n",
        "The encoder processes the input sequence and compresses the information into a context vector (also known as the state vector). This vector aims to encapsulate the information for all the input elements in order to help the decoder make accurate predictions. In most cases, the encoder is a Recurrent Neural Network (RNN) or one of its variants like LSTM or GRU.\n",
        "\n",
        "### Decoder\n",
        "The decoder is trained to generate the output sequence by predicting the next element based on the previous elements and the context vector from the encoder. It continues generating elements of the sequence until it produces an end-of-sequence token, signaling that the output is complete. Similar to the encoder, the decoder is often an RNN or an advanced variant.\n",
        "\n",
        "Together, these components enable the model to handle complex sequence generation tasks, often surpassing the capabilities of models that do not have such a structured approach to handling sequences.\n"
      ],
      "metadata": {
        "id": "PYhc9ZE8GP2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random"
      ],
      "metadata": {
        "id": "t42lShHxJeOx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple Seq2Seq model using PyTorch\n",
        "# For this example, we will consider a simple case study of reversing a sequence\n",
        "\n",
        "# Sample data: a list of sequences (for simplicity, we use numbers here)\n",
        "input_sequences = [\n",
        "    [1, 2, 3, 4, 5],\n",
        "    [6, 7, 8, 9, 10],\n",
        "    [11, 12, 13, 14, 15],\n",
        "    [16, 17, 18, 19, 20],\n",
        "    [21, 22, 23, 24, 25]\n",
        "]\n"
      ],
      "metadata": {
        "id": "R3B3o9ezJdba"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reverse the sequences to create target sequences\n",
        "target_sequences = [list(reversed(seq)) for seq in input_sequences]\n",
        "print(target_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7iOXwBtJvl8",
        "outputId": "27eb54e2-7376-4a12-ef30-184c4b9d6fa5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5, 4, 3, 2, 1], [10, 9, 8, 7, 6], [15, 14, 13, 12, 11], [20, 19, 18, 17, 16], [25, 24, 23, 22, 21]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder Architecture\n",
        "\n",
        "Here, we define a simple Encoder class that extends `nn.Module`, PyTorch's base class for all neural network modules. Our encoder is a key component in sequence-to-sequence models, where it processes the input sequence and compresses the information into a context vector (the final hidden state).\n",
        "\n",
        "### Components of the Encoder:\n",
        "\n",
        "- **Embedding Layer**: This layer converts input tokens (usually integers representing words) into dense vectors of fixed size. It's a way to handle the vast dimensionality of language data and reduce it to a more manageable form.\n",
        "  \n",
        "- **GRU Layer**: The Gated Recurrent Unit (GRU) is a type of RNN that can capture dependencies at different time scales. It processes the sequence step by step, updating its hidden state at each time step.\n",
        "\n",
        "### The `forward` Method:\n",
        "\n",
        "The `forward` function is where the actual computation of the module occurs. It takes two arguments: `input` and `hidden`:\n",
        "- `input` is the sequence of tokens that are to be encoded.\n",
        "- `hidden` is the initial hidden state (usually starting as zeros).\n",
        "\n",
        "The `forward` function performs the following steps:\n",
        "1. It passes the input through the embedding layer to get dense representations.\n",
        "2. It reshapes the embedded input to fit the expected input dimensions of the GRU.\n",
        "3. It processes the input through the GRU layer, which updates the hidden state.\n",
        "\n",
        "The GRU outputs the `output` for each input along with the updated `hidden` state, which is then returned by the function.\n",
        "\n",
        "### Initialization of Hidden State:\n",
        "\n",
        "The `initHidden` method initializes the hidden state to zeros. This state will be updated as the GRU processes the input sequence.\n",
        "\n",
        "This encoder architecture is commonly used as the first component in sequence-to-sequence models, which aim to transform a given sequence into a new domain, such as translating sentences from one language to another.\n"
      ],
      "metadata": {
        "id": "C_u2wGFhNP-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple Encoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size)"
      ],
      "metadata": {
        "id": "kKhFDVV3J-bk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder Architecture\n",
        "\n",
        "The Decoder is the second component of our sequence-to-sequence model, designed to generate an output sequence from the context vector provided by the Encoder.\n",
        "\n",
        "### Components of the Decoder:\n",
        "\n",
        "- **Embedding Layer**: Similar to the Encoder, the embedding layer here transforms the indices of the output tokens into dense vectors.\n",
        "\n",
        "- **GRU Layer**: The GRU works just like in the Encoder, but here it's generating a sequence rather than encoding it. It starts with the context vector from the Encoder as its initial hidden state.\n",
        "\n",
        "- **Linear Layer**: This layer maps the output of the GRU to the space of the possible output tokens.\n",
        "\n",
        "- **Softmax Layer**: The softmax function is applied to the linear layer's output to obtain a probability distribution over all possible output tokens.\n",
        "\n",
        "### The `forward` Method:\n",
        "\n",
        "The `forward` function processes the inputs through the following steps:\n",
        "1. The input token is embedded and reshaped to fit the expected input dimensions of the GRU.\n",
        "2. The GRU processes the input, and the hidden state is updated.\n",
        "3. The output from the GRU is passed through a linear layer and then through a softmax layer to predict the probability distribution of the next token in the sequence.\n",
        "\n",
        "### Generating Output Sequences:\n",
        "\n",
        "The Decoder's job is to generate an output sequence one token at a time. It continues generating tokens until it reaches an end-of-sequence token or some predefined limit. At each step, it uses the output token as the next input token.\n",
        "\n",
        "This simple decoder architecture is a fundamental part of many sequence generation tasks such as machine translation, where the model needs to produce a sequence of words in the target language.\n"
      ],
      "metadata": {
        "id": "mGM5SwRQNdUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple Decoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = torch.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "ZYw0YF_rKBtG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "input_size = 26  # Assuming a vocabulary size of 26 (like the English alphabet)\n",
        "hidden_size = 256\n",
        "output_size = 26"
      ],
      "metadata": {
        "id": "j-Ms1DR3KEzJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize encoder and decoder models\n",
        "encoder = Encoder(input_size, hidden_size)\n",
        "decoder = Decoder(hidden_size, output_size)"
      ],
      "metadata": {
        "id": "EgmX2lTFKJcd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training loop\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=5):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[:, ei], encoder_hidden)\n",
        "\n",
        "    decoder_input = torch.tensor([[0]])  # SOS token\n",
        "\n",
        "    for di in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, encoder_hidden)\n",
        "        topv, topi = decoder_output.topk(1)\n",
        "        decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        loss += criterion(decoder_output, target_tensor[:, di])\n",
        "        if decoder_input.item() == 1:  # EOS token\n",
        "            break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "id": "RII9g-RnKNkO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Optimizers\n",
        "encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.01)\n",
        "decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "L__uT3bNKQ2X"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert input and target sequences to tensors\n",
        "input_tensors = [torch.tensor(seq, dtype=torch.long) for seq in input_sequences]\n",
        "target_tensors = [torch.tensor(seq, dtype=torch.long) for seq in target_sequences]"
      ],
      "metadata": {
        "id": "G-57l_ijKULu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model with a small number of epochs for demonstration purposes\n",
        "for epoch in range(1):\n",
        "    total_loss = 0\n",
        "    for input_tensor, target_tensor in zip(input_tensors, target_tensors):\n",
        "        loss = train(input_tensor.unsqueeze(0), target_tensor.unsqueeze(0), encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        total_loss += loss\n",
        "        print(f'Epoch {epoch}, Loss: {loss}')\n",
        "    print(f'Epoch {epoch} completed, Total Loss: {total_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xaB3QWOKXs9",
        "outputId": "0814f7e9-d678-48d4-d7c3-b89f353a6af5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 3.160747766494751\n",
            "Epoch 0, Loss: 3.3049395084381104\n",
            "Epoch 0, Loss: 3.376070737838745\n",
            "Epoch 0, Loss: 3.3989901542663574\n",
            "Epoch 0, Loss: 3.061946392059326\n",
            "Epoch 0 completed, Total Loss: 16.30269455909729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert tensor to list\n",
        "def tensor_to_list(tensor):\n",
        "    return tensor.detach().cpu().tolist()"
      ],
      "metadata": {
        "id": "_hb3D9H3Ktb0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming max_length is the maximum sequence length that you expect\n",
        "max_length = 5\n",
        "\n",
        "# Function to generate predictions from the model\n",
        "def predict(input_tensor, encoder, decoder, max_length=max_length):\n",
        "    with torch.no_grad():\n",
        "        input_length = input_tensor.size(0)\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        # Encoding\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "\n",
        "        # Decoding\n",
        "        decoder_input = torch.tensor([[0]])  # SOS token\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        predicted_seq = []\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == 1:  # EOS token\n",
        "                break\n",
        "            else:\n",
        "                predicted_seq.append(topi.item())\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return predicted_seq"
      ],
      "metadata": {
        "id": "NqHAwd2oOlCd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After training, visualize some predictions\n",
        "print(\"Visualizing Predictions after Training:\")\n",
        "for i in range(min(5, len(input_tensors))):\n",
        "    input_sequence = tensor_to_list(input_tensors[i])\n",
        "    target_sequence = tensor_to_list(target_tensors[i])\n",
        "    predicted_sequence = predict(input_tensors[i], encoder, decoder)\n",
        "\n",
        "    print(f\"Input Sequence: {input_sequence}\")\n",
        "    print(f\"Target Sequence: {target_sequence}\")\n",
        "    print(f\"Predicted Sequence: {predicted_sequence}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzR95-hPOrxB",
        "outputId": "bd857aa3-e9ed-44c8-cab8-29e42fbb50c5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualizing Predictions after Training:\n",
            "Input Sequence: [1, 2, 3, 4, 5]\n",
            "Target Sequence: [5, 4, 3, 2, 1]\n",
            "Predicted Sequence: [25, 7, 23, 25, 7]\n",
            "\n",
            "Input Sequence: [6, 7, 8, 9, 10]\n",
            "Target Sequence: [10, 9, 8, 7, 6]\n",
            "Predicted Sequence: [5, 5, 14, 12, 25]\n",
            "\n",
            "Input Sequence: [11, 12, 13, 14, 15]\n",
            "Target Sequence: [15, 14, 13, 12, 11]\n",
            "Predicted Sequence: [15, 5, 5, 5, 14]\n",
            "\n",
            "Input Sequence: [16, 17, 18, 19, 20]\n",
            "Target Sequence: [20, 19, 18, 17, 16]\n",
            "Predicted Sequence: [25, 7, 23, 25, 7]\n",
            "\n",
            "Input Sequence: [21, 22, 23, 24, 25]\n",
            "Target Sequence: [25, 24, 23, 22, 21]\n",
            "Predicted Sequence: [15]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WAzNwMY1OtW7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}